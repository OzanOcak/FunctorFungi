[{"content":"Advanced SQL Queries with Drizzle In modern web development, efficiently managing database interactions is crucial for building responsive applications. Drizzle, a powerful TypeScript ORM, provides developers with a robust toolkit for querying and observing database tables. One of its standout features is the ease of use in executing SQL queries, allowing for seamless data retrieval and manipulation.\nnpx drizzle-kit studio To streamline your database interactions, you can utilize npx drizzle-kit studio. This tool serves as an interactive environment where you can query and observe your database tables. It simplifies the process of testing and refining your SQL queries, enabling you to visualize the data structure and understand relationships between tables more intuitively.\nYou can also see database diagram and source code of project in github\nexecute() vs returning() When working with Drizzle, you often encounter two primary methods for executing queries: execute() and returning(). Understanding the difference between these methods is essential for effective data handling.\nexecute(): This method is typically used for sending a query to the database and receiving the results directly. It is useful when you need to retrieve data without any specific requirements for the returned format. For example, in an API function like getUserById, you might implement it as follows:\ngetUserById: async (userId: number) =\u0026gt; { return await db.select().from(user).where(eq(user.id, userId)).execute(); }; returning(): In contrast, returning() is employed when you want more control over the data you retrieve after performing an operation, such as an insert or update. This method allows you to specify which fields to return, providing a more tailored response based on your application\u0026rsquo;s needs. By leveraging the capabilities of Drizzle and understanding these methods, you can create advanced SQL queries that enhance your application\u0026rsquo;s performance and user experience. In the following sections, we\u0026rsquo;ll dive deeper into practical examples and best practices for using Drizzle in your projects.\nconst result = await db .insert(product) .values({ name: \u0026#34;Coke\u0026#34;, description: \u0026#34;Coca Cola\u0026#34;, }) .returning({ name: true, description: true, }); Basic 1. Basic SELECT Statement To select all cart items:\ndb.select().from(cartItems); 2. SELECT with WHERE Clause To select cart items for a specific cart ID:\ndb.select().from(cartItems).where(eq(cartItems.cartId, \u0026#34;your-cart-id\u0026#34;)); // UUID 3. Filtering Results with AND To select reviews for a specific product by a specific user:\ndb.select() .from(reviews) .where( and( eq(reviews.productId, \u0026#34;your-product-id\u0026#34;), // UUID eq(reviews.userId, \u0026#34;your-user-id\u0026#34;) // UUID ) ); 4. Filtering Results with OR To select reviews that are either from a specific user or have a specific rating:\ndb.select() .from(reviews) .where( or( eq(reviews.userId, \u0026#34;your-user-id\u0026#34;), // UUID eq(reviews.rating, 5) ) ); 5. Filtering Results with NOT To select addresses that do not belong to a specific user:\ndb.select() .from(addresses) .where(not(eq(addresses.userId, \u0026#34;your-user-id\u0026#34;))); //UUID Each query uses db.select() to initiate the selection. The .from() method specifies the table. The .where() method adds conditions, using eq(), and(), or(), and not() for filtering. Replace \u0026lsquo;your-cart-id-here\u0026rsquo;, \u0026lsquo;your-product-id-here\u0026rsquo;, and \u0026lsquo;your-user-id-here\u0026rsquo; with actual UUID values as needed.\n6. Sorting Results with ORDER BY To select all reviews and sort them by rating in descending order:\ndb.select().from(reviews).orderBy(desc(reviews.rating)); // Sort by rating in descending order 7. Combining ORDER BY with LIMIT To select the top 5 highest-rated reviews for a specific product:\ndb.select() .from(reviews) .where(eq(reviews.productId, \u0026#34;your-product-id\u0026#34;)) // Replace with actual UUID .orderBy(desc(reviews.rating)) // Sort by rating in descending order .limit(5); // Limit to 5 results 8. Sorting with Multiple Columns To select cart items and sort them first by quantity in ascending order and then by productId in descending order:\ndb.select().from(cartItems).orderBy( asc(cartItems.quantity), // Sort by quantity in ascending order desc(cartItems.productId) // Then by productId in descending order ); The .orderBy() method is used to specify the sorting criteria. You can use asc() for ascending order and desc() for descending order. The .limit() method restricts the number of results returned. Replace \u0026lsquo;your-product-id-here\u0026rsquo; with the actual UUID when executing the queries.\n9. Using Aggregate Functions COUNT() To count the number of reviews for a specific product:\ndb.select({ count: countDistinct(reviews.id), // Count the number of review IDs }) .from(reviews) .where(eq(reviews.productId, \u0026#34;your-product-id\u0026#34;)); // Replace with actual UUID SUM(); To calculate the total amount of payments made:\nconst totalPayments = await db .select({ total: sum(payments.amount), // Sum of all payment amounts }) .from(payments) .execute(); AVG(); To calculate the average rating for a specific product:\nconst averageRating = await db .select({ average: avg(reviews.rating), // Average of ratings }) .from(reviews) .where(eq(reviews.productId, \u0026#34;your-product-id-here\u0026#34;)) // Replace with actual UUID .execute(); MIN() To find the minimum payment amount:\nconst minPayment = await db .select({ minimum: min(payments.amount), // Minimum payment amount }) .from(payments) .execute(); MAX() To find the maximum rating for a specific product:\nconst maxRating = await db .select({ maximum: max(reviews.rating), // Maximum rating }) .from(reviews) .where(eq(reviews.productId, \u0026#34;your-product-id-here\u0026#34;)) // Replace with actual UUID .execute(); 10. Grouping Results with GROUP BY To group reviews by user and count how many reviews each user has made:\ndb.select({ userId: reviews.userId, reviewCount: count(reviews.id), // Count reviews for each user }) .from(reviews) .groupBy(reviews.userId); // Group by userId 11. Filtering Groups with HAVING To find users who have made more than 3 reviews:\ndb.select({ userId: reviews.userId, reviewCount: count(reviews.id), // Count reviews for each user }) .from(reviews) .groupBy(reviews.userId) // Group by userId .having(gt(count(reviews.id), 3)); // Filter groups with more than 3 reviews Use count(), sum(), avg(), min(), and max() to perform aggregate calculations. The .groupBy() method is used to group results based on specified columns. The .having() method allows filtering of grouped results, using conditions like gt() (greater than). Replace \u0026lsquo;your-product-id-here\u0026rsquo; with actual UUID values as needed.\nIntermediate 12. Inner Join To select cart items along with the associated products:\ndb.select() .from(cartItems) .innerJoin(products, eq(cartItems.productId, products.id)); // Join with products table 13. Left Join To select all cart items and their associated products, including cart items that may not have a corresponding product:\ndb.select() .from(cartItems) .leftJoin(products, eq(cartItems.productId, products.id)); 14. Right Join To select all products and their associated cart items, including products that may not have been added to any cart:\ndb.select() .from(products) .rightJoin(cartItems, eq(cartItems.productId, products.id)); 15. Full Outer Join To select all cart items and products, including those that may not have matches in either table:\ndb.select() .from(cartItems) .fullOuterJoin(products, eq(cartItems.productId, products.id)); Each query uses the .select() method to initiate the selection. The .from() method specifies the primary table, while the join methods (innerJoin, leftJoin, rightJoin, fullOuterJoin, and crossJoin) specify how to combine it with other tables. The eq() function is used to define the condition for joining tables.\n16. Nested Subqueries Queries To find all products that have reviews with an average rating above 4.0:\ndb.select() .from(products) .where( inArray( products.id, db .select({ productId: avg(reviews.rating) }) .from(reviews) .groupBy(reviews.productId) .having(gt(avg(reviews.rating), 4.0)) ) ); 17. Correlated Subqueries To find all users who have written reviews for products with an average rating above 4.0:\ndb.select() .from(users) .where( exists( db .select() .from(reviews) .where( eq(reviews.userId, users.id), // Correlated subquery linking userId inArray( reviews.productId, db .select({ productId: avg(reviews.rating) }) .from(reviews) .groupBy(reviews.productId) .having(gt(avg(reviews.rating), 4.0)) ) ) ) ); Nested Queries: The first example uses a subquery to find product IDs that have an average rating greater than 4.0. The outer query then retrieves products that match these IDs using inArray(). Correlated Subqueries: The second example retrieves users who have written reviews for products with an average rating above 4.0. The subquery correlates to the outer query by using users.id to link to reviews.userId.\n18. UNION To combine results from two different queries (e.g., retrieves user IDs from both reviews and wishlists):\ndb.select({ userId: reviews.userId }) .from(reviews) .union(db.select({ userId: wishlists.userId }).from(wishlists)); // get user IDs from wishlists 19. UNION ALL To combine results from two different queries without removing duplicates (e.g., retrieves all user IDs from reviews and wishlists):\ndb.select({ userId: reviews.userId }) .from(reviews) .unionAll( db.select({ userId: wishlists.userId }).from(wishlists) // get user IDs from wishlists ); 20. INTERSECT To find user IDs that exist in both reviews and wishlists:\ndb.select({ userId: reviews.userId }) .from(reviews) .intersect( db.select({ userId: wishlists.userId }).from(wishlists) // get user IDs from wishlists ); 21. EXCEPT To find user IDs from reviews that do not exist in wishlists:\ndb.select({ userId: reviews.userId }) .from(reviews) .except( db.select({ userId: wishlists.userId }).from(wishlists) // get user IDs from wishlists ); UNION: Combines the results of two queries while removing duplicates. UNION ALL: Combines the results of two queries without removing duplicates. INTERSECT: Retrieves common results from two queries. EXCEPT: Retrieves results from the first query that do not exist in the second query.\n22. INSERT Statements Inserting a New Cart Item To insert a new item into the cart_items table:\ndb.insert(product).values({ name: \u0026#34;Coke\u0026#34;, description: \u0026#34;Coca Cola\u0026#34;, price: 1.99, stockQuantity: 120, }); 23. UPDATE Statements Updating a Review To update the comment and rating of a specific review:\ndb.update(reviews) .set({ rating: 5, // New rating comment: \u0026#34;Updated comment text.\u0026#34;, // Updated comment }) .where(eq(reviews.id, \u0026#34;your-review-id-here\u0026#34;)); // Replace with actual UUID 24. DELETE Statements Deleting a Wishlist Item To delete a specific item from the wishlist_items table:\ndb.delete(wishlistItems).where( eq(wishlistItems.id, \u0026#34;your-wishlist-item-id-here\u0026#34;) ); // Replace with actual UUID Explanation INSERT: The insert() method is used to add a new record to a table. The .values() method specifies the data to be inserted. UPDATE: The update() method modifies existing records in a table. The .set() method specifies the new values, and the .where() method identifies which record to update. DELETE: The delete() method removes records from a table. The .where() method specifies which record(s) to delete.\nUnderstanding ACID Properties ACID stands for:\nAtomicity: Transactions are all-or-nothing. If one part of the transaction fails, the entire transaction fails. Consistency: Transactions must leave the database in a consistent state, adhering to all rules and constraints. Isolation: Transactions should not interfere with one another. Each transaction operates independently. Durability: Once a transaction is committed, it remains so, even in the event of a system failure. COMMIT and ROLLBACK Statements In Drizzle ORM, you can manage transactions using COMMIT and ROLLBACK to ensure that your operations adhere to ACID properties.\n25.Transaction db.transaction(); try { // Insert a new cart item await transaction .insert(cartItems) .values({ id: \u0026#34;your-cart-item-uuid\u0026#34;, // Replace with actual UUID cartId: \u0026#34;your-cart-id\u0026#34;, // Replace with actual UUID productId: \u0026#34;your-product-id\u0026#34;, // Replace with actual UUID quantity: 1, }) .execute(); // Update a product\u0026#39;s stock (for example) await transaction .update(products) .set({ stock: decrement(products.stock, 1) }) // Decrease stock by 1 .where(eq(products.id, \u0026#34;your-product-id\u0026#34;)) // Replace with actual UUID .execute(); // Commit the transaction await transaction.commit(); } catch (error) { console.error(\u0026#34;Transaction failed:\u0026#34;, error); // Rollback the transaction in case of error await transaction.rollback(); } 26.Savepoints Savepoints allow you to set a point within a transaction to which you can roll back without affecting the entire transaction.\nExample of Using Savepoints\ndb.transaction(); try { // Start the transaction await transaction.begin(); // Insert a new cart item await transaction .insert(cartItems) .values({ id: \u0026#34;your-cart-item-uuid\u0026#34;, // Replace with actual UUID cartId: \u0026#34;your-cart-id\u0026#34;, // Replace with actual UUID productId: \u0026#34;your-product-id\u0026#34;, // Replace with actual UUID quantity: 1, }) .execute(); // Create a savepoint await transaction.savepoint(\u0026#34;afterInsert\u0026#34;); // Update a product\u0026#39;s stock await transaction .update(products) .set({ stock: decrement(products.stock, 1) }) // Decrease stock by 1 .where(eq(products.id, \u0026#34;your-product-id\u0026#34;)) // Replace with actual UUID .execute(); // If something goes wrong, roll back to the savepoint // Uncomment to simulate error handling // throw new Error(\u0026#39;Simulated error\u0026#39;); // Commit the transaction if everything is fine await transaction.commit(); } catch (error) { console.error(\u0026#34;Transaction failed:\u0026#34;, error); // Rollback to the savepoint if needed await transaction.rollbackTo(\u0026#34;afterInsert\u0026#34;); // Or rollback the entire transaction // await transaction.rollback(); } Explanation COMMIT: Saves all changes made during the transaction. In the example, if all operations succeed, the transaction is committed. ROLLBACK: Reverts any changes made during the transaction if an error occurs. You can roll back to the last savepoint or the entire transaction. Savepoints: Allow you to set a point within a transaction. If an error occurs after a savepoint, you can roll back to that point rather than starting over from the beginning.\n27. Indexes What Are Indexes? Indexes are special database structures that improve the speed of data retrieval operations on a database table. They work similarly to an index in a book, allowing the database to find and access data without scanning every row in the table.\nBenefits of Indexes Faster Query Performance: Indexes can significantly reduce the time it takes to retrieve data, especially for large tables. Efficient Sorting: They help speed up the sorting of results, particularly when using ORDER BY clauses. Improved Filtering: Indexes enhance the performance of queries that filter data using WHERE clauses. Creating and Dropping Indexes In Drizzle ORM, you can create and drop indexes using the following methods:\nCreating an Index To create an index on a specific column (e.g., on the productId column in the reviews table):\nawait db.schema.createIndex(\u0026#34;idx_reviews_productId\u0026#34;, reviews, { columns: [reviews.productId], }); This creates an index named idx_reviews_productId on the productId column of the reviews table.\nDropping an Index To drop an index when it\u0026rsquo;s no longer needed:\nawait db.schema.dropIndex(\u0026#34;idx_reviews_productId\u0026#34;); This removes the index named idx_reviews_productId.\nImpact of Indexes on Performance While indexes can greatly improve read performance, they also have some trade-offs:\nPositive Impacts Faster Query Execution: Queries that use indexed columns in WHERE, JOIN, and ORDER BY clauses run faster. Reduced I/O Operations: Indexes allow the database to read only the relevant rows instead of scanning the entire table. Negative Impacts Slower Write Operations: Insert, update, and delete operations can slow down because the database must also update the index. Increased Storage Space: Indexes consume additional disk space, which can be significant for large tables or multiple indexes. Conclusion Indexes are powerful tools for enhancing database performance, especially for read-heavy applications. However, it\u0026rsquo;s crucial to balance the benefits of faster query performance against the overhead they introduce for write operations and storage requirements. Careful planning and analysis are necessary to determine when and where to use indexes effectively.\nAdvanced Views in Databases Views are virtual tables that provide a way to represent the result of a query as if it were a table. They can simplify complex queries, enhance security by restricting access to certain data, and allow users to work with a simplified representation of the data.\nCreating and Using Views Creating a View To create a view in Drizzle ORM, you can define it based on a query. For example, creating a view to show the average rating of each product:\nawait db.schema.createView(\u0026#34;product_average_ratings\u0026#34;, { select: { productId: reviews.productId, averageRating: avg(reviews.rating), }, from: reviews, groupBy: reviews.productId, }); This creates a view named product_average_ratings that calculates the average rating for each product.\nUsing a View To query data from a view:\nconst productRatings = await db .select() .from(\u0026#34;product_average_ratings\u0026#34;) .execute(); This retrieves the average ratings from the product_average_ratings view.\nUpdatable Views Updatable views allow you to perform INSERT, UPDATE, and DELETE operations on the view, which will affect the underlying tables. However, not all views are updatable. A view is typically updatable if it meets certain conditions, such as:\nIt is based on a single table. It does not include aggregate functions. It does not use DISTINCT, GROUP BY, or HAVING. Example of an Updatable View If you create a simple view on the reviews table:\nawait db.schema.createView(\u0026#34;user_reviews\u0026#34;, { select: { id: reviews.id, userId: reviews.userId, productId: reviews.productId, rating: reviews.rating, comment: reviews.comment, }, from: reviews, }); You can update the view:\nawait db .update(\u0026#34;user_reviews\u0026#34;) .set({ rating: 4 }) // Update the rating .where(eq(\u0026#34;id\u0026#34;, \u0026#34;your-review-id-here\u0026#34;)) // Specify the review ID .execute(); Materialized Views Materialized views are similar to regular views but store the result of the query physically. This allows for faster access to data, as the results do not need to be recalculated on each query. However, they require maintenance to keep the data up to date.\nCreating a Materialized View To create a materialized view (if supported by the database), you might use a command like this (note that Drizzle ORM may not directly support creating materialized views, and you may need to use raw SQL):\n``sql CREATE MATERIALIZED VIEW product_ratings_mv AS SELECT productId, AVG(rating) AS averageRating FROM reviews GROUP BY productId;\n#### Refreshing a Materialized View To update the data in a materialized view, you typically need to refresh it: ``sql REFRESH MATERIALIZED VIEW product_ratings_mv; Conclusion Views: Simplify complex queries and provide a secure interface to the data. Updatable Views: Allow data manipulation through the view, affecting the underlying tables. Materialized Views: Store query results physically for faster access, requiring periodic refreshes to update the data. Using views effectively can enhance both performance and security in your database applications!\n","permalink":"http://localhost:1313/posts/advanced-sql-queries-with-drizzle/","summary":"Advanced SQL Queries with Drizzle In modern web development, efficiently managing database interactions is crucial for building responsive applications. Drizzle, a powerful TypeScript ORM, provides developers with a robust toolkit for querying and observing database tables. One of its standout features is the ease of use in executing SQL queries, allowing for seamless data retrieval and manipulation.\nnpx drizzle-kit studio To streamline your database interactions, you can utilize npx drizzle-kit studio.","title":"Advanced Sql Queries With Drizzle"},{"content":"In this blog post, we will walk through the process of setting up Drizzle ORM on a typed RPC server which we have built previous plog post, using PostgreSQL. We will cover the installation of necessary packages, configuration files, and how to seed the database. Let’s get started!\nInstall Required Packages First, we need to install the necessary dependencies for Drizzle ORM and PostgreSQL. Open your terminal and run the following command:\nnpm install drizzle-orm pg dotenv npm install -D drizzle-kit @types/pg nodemon tsx This command installs Drizzle ORM for database interactions, the PostgreSQL client, and development tools like nodemon for automatic server restarts.\nSet Up the Project Structure Next, we’ll create a basic project structure. Run the following commands to create the required directories and files:\nmkdir db touch db/dbConn.ts db/migrate.ts db/schema.ts This creates a db directory where we will store our database connection, migration scripts, and schema definitions.\nCreate Configuration Files We will create three configuration files in the root of the project directory, at the same level as package.json: .env, docker-compose.yaml, and drizzle.config.ts.\nDocker Configuration Here’s an example docker-compose.yaml file to set up a PostgreSQL database:\nservices: db: container_name: authapp image: postgres:16 environment: - POSTGRES_USER=${DB_USERNAME} - POSTGRES_PASSWORD=${DB_PASSWORD} - POSTGRES_DB=${DB_NAME} ports: - ${DB_PORT}:5432 volumes: - db-data:/var/lib/postgresql/data # adminer: # image: adminer # restart: always # ports: # - 8080:8080 volumes: db-data: In this configuration, we define a PostgreSQL service with environment variables that will be populated from our .env file. Note that we commented out the Adminer service, as it is not needed for our setup with Drizzle ORM.\nEnvironment Variables Next, create a .env file to store environment variables:\nDB_HOST=localhost DB_USERNAME=postgres DB_PASSWORD=postgres DB_NAME=database DB_PORT=5432 PORT=4000 DATABASE_URL=postgres://postgres:postgres@localhost:5432/database This file contains the configuration for connecting to your PostgreSQL database. Make sure to adjust the values as necessary for your setup.\nDrizzle Configuration Now, let\u0026rsquo;s set up the Drizzle configuration by creating drizzle.config.ts:\nimport dotenv from \u0026#34;dotenv\u0026#34;; import { defineConfig } from \u0026#34;drizzle-kit\u0026#34;; dotenv.config(); // Load environment variables export default defineConfig({ dialect: \u0026#34;postgresql\u0026#34;, // \u0026#34;mysql\u0026#34; | \u0026#34;sqlite\u0026#34; | \u0026#34;postgresql\u0026#34; schema: \u0026#34;./src/db/schema/index.ts\u0026#34;, out: \u0026#34;src/drizzle\u0026#34;, // drizzle folder should be under src directory dbCredentials: { url: process.env.DATABASE_URL!, }, }); This configuration file tells Drizzle ORM how to connect to the database and where to find the schema.\nUpdate Package Scripts Next, we’ll add some scripts to our package.json to streamline our development workflow. Here’s how to modify the scripts section:\n\u0026#34;scripts\u0026#34;: { \u0026#34;dev:api\u0026#34;: \u0026#34;tsx src/api/index.ts\u0026#34;, \u0026#34;dev:client\u0026#34;: \u0026#34;tsx src/client/index.ts\u0026#34;, \u0026#34;dev\u0026#34;: \u0026#34;nodemon --exec ts-node src/server.ts\u0026#34;, \u0026#34;seed\u0026#34;: \u0026#34;tsx src/db/seed.ts\u0026#34;, \u0026#34;build\u0026#34;: \u0026#34;tsc\u0026#34;, \u0026#34;db:generate\u0026#34;: \u0026#34;npx drizzle-kit generate --config=\u0026#39;./drizzle.config.ts\u0026#39;\u0026#34;, \u0026#34;db:push\u0026#34;: \u0026#34;npx ts-node src/db/migrate.ts\u0026#34;, \u0026#34;migrate\u0026#34;: \u0026#34;npx drizzle-kit generate --config=\u0026#39;./drizzle.config.ts\u0026#39; \u0026amp;\u0026amp; npx ts-node src/db/migrate.ts\u0026#34; } These scripts allow you to run the API, client, database migrations, and seeding commands easily.\nDatabase Connection We start by establishing a connection to our PostgreSQL database using the dbConn.ts file. Here’s how the code looks:\n// db/dbConn.ts import dotenv from \u0026#34;dotenv\u0026#34;; import { Pool } from \u0026#34;pg\u0026#34;; import { drizzle } from \u0026#34;drizzle-orm\u0026#34;; import { schema } from \u0026#34;./schema\u0026#34;; dotenv.config(); // Load environment variables // PostgreSQL connection configuration const pool = new Pool({ host: process.env.DB_HOST!, port: Number(process.env.DB_PORT!), user: process.env.DB_USERNAME!, password: process.env.DB_PASSWORD!, database: process.env.DB_NAME!, }); // Initialize the database connection const db = drizzle(pool, { schema }); // Connection state let isConnected = false; // Function to connect the database export async function connectDatabase() { if (!isConnected) { try { await pool.connect(); // Connect to the database isConnected = true; // Update the connection state console.log(\u0026#34;Connected to PostgreSQL database\u0026#34;); } catch (err) { console.error(\u0026#34;Connection error\u0026#34;, err); } } else { console.log(\u0026#34;Already connected to PostgreSQL database\u0026#34;); } } // Call the connect function connectDatabase(); // Export the client and db for use in other parts of your application export { pool, db }; In this file:\nWe load environment variables using dotenv. We configure a connection pool to PostgreSQL. We create a Drizzle ORM instance with the database connection and schema.\nDatabase Migrations Next, we need to perform database migrations to create the necessary tables. The migrate.ts file will handle this:\n// db/migrate.ts import { pool } from \u0026#39;./dbConn\u0026#39;; import { migrate } from \u0026#39;drizzle-orm\u0026#39;; const migrateDatabase = async () =\u0026gt; { const client = await pool.connect(); // Get a client from the pool try { console.log(\u0026#34;Connected to PostgreSQL database for migrations.\u0026#34;); // Perform the migrations await migrate(db, { migrationsFolder: resolve(__dirname, \u0026#34;../drizzle\u0026#34;) }); console.log(\u0026#34;Migrations completed successfully.\u0026#34;); } catch (error) { console.error(\u0026#34;Migration error:\u0026#34;, error); } finally { client.release(); // Ensure the client is closed console.log(\u0026#34;PostgreSQL client disconnected.\u0026#34;); process.exit(0); }; migrateDatabase(); Here, we:\nConnect to the database and execute migrations defined in the specified folder. Ensure the client is released after the operation, preventing resource leaks.\nDefining the Schema We define our database schema in the schema directory. For example, the category.ts file defines a category table:\n// db/schema/category.ts import { pgTable, serial, varchar } from \u0026#34;drizzle-orm\u0026#34;; export const category = pgTable(\u0026#34;category\u0026#34;, { id: serial(\u0026#34;id\u0026#34;).primaryKey(), name: varchar(\u0026#34;name\u0026#34;, { length: 255 }).notNull().unique(), }); This schema represents a simple category table with an auto-incrementing id and a unique name.\nSeeding the Database Now, let\u0026rsquo;s seed our database with initial data. We have our seed data defined in JSON format:\n// db/seeds/data/categories.ts [ { \u0026#34;name\u0026#34;: \u0026#34;Italy\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;France\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;Poland\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;Germany\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;Holland\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;Spain\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;Norway\u0026#34; } ] Next, we implement the seeding logic in category.ts:\n// db/seeds/category.ts import { category } from \u0026#34;../schema/category\u0026#34;; import { DB } from \u0026#34;drizzle-orm\u0026#34;; const categories = require(\u0026#34;./data/categories.json\u0026#34;); export async function seed(db: DB) { await db.insert(category).values(categories); } Finally, we create a seed.ts file to reset the tables and run the seeding function:\n// db/seed.ts import { db } from \u0026#34;./dbConn\u0026#34;; import { category } from \u0026#34;./schema/category\u0026#34;; import { seed as categorySeed } from \u0026#34;./seeds/category\u0026#34;; async function resetTable(db: DB, table: Table) { return db.execute(sql`truncate table ${table} restart identity cascade`); } async function main() { for (const table of [category]) { await resetTable(db, table); } await categorySeed(db); } main() .catch((e) =\u0026gt; { console.error(e); process.exit(1); }) .finally(async () =\u0026gt; { console.log(\u0026#34;Seeding done!\u0026#34;); process.exit(0); }); This script truncates the existing data and inserts the new seed data.\nRunning the Setup Now that everything is set up, here’s how to run your application:\nStart Docker: Spin up your PostgreSQL container:\ndocker compose up -d Run the API: Start your API server:\nnpm run dev:api Migrate the Database: Apply the migrations:\nnpm run migrate Seed the Database: Populate the database with initial data:\nnpm run seed Run the Client: Start your client application:\nnpm run dev:client Querying the Database Once your server is running, you can query the database through your RPC API. The API will return a JSON response with the seeded data:\n[ { \u0026#34;id\u0026#34;: 1, \u0026#34;name\u0026#34;: \u0026#34;Italy\u0026#34; }, { \u0026#34;id\u0026#34;: 2, \u0026#34;name\u0026#34;: \u0026#34;France\u0026#34; }, { \u0026#34;id\u0026#34;: 3, \u0026#34;name\u0026#34;: \u0026#34;Poland\u0026#34; }, { \u0026#34;id\u0026#34;: 4, \u0026#34;name\u0026#34;: \u0026#34;Germany\u0026#34; }, { \u0026#34;id\u0026#34;: 5, \u0026#34;name\u0026#34;: \u0026#34;Holland\u0026#34; }, { \u0026#34;id\u0026#34;: 6, \u0026#34;name\u0026#34;: \u0026#34;Spain\u0026#34; }, { \u0026#34;id\u0026#34;: 7, \u0026#34;name\u0026#34;: \u0026#34;Norway\u0026#34; } ] Using Drizzle Studio To visualize your database schema and data, you can use Drizzle Studio by running:\nnpx drizzle-kit studio This will provide a user-friendly interface to interact with your database.\nConclusion You have successfully set up a typed RPC API connected to a PostgreSQL database using Drizzle ORM. You learned how to configure the database connection, create migrations, seed initial data, and interact with the database via an API. This setup provides a robust foundation for building scalable applications.\n","permalink":"http://localhost:1313/posts/drizzle/","summary":"In this blog post, we will walk through the process of setting up Drizzle ORM on a typed RPC server which we have built previous plog post, using PostgreSQL. We will cover the installation of necessary packages, configuration files, and how to seed the database. Let’s get started!\nInstall Required Packages First, we need to install the necessary dependencies for Drizzle ORM and PostgreSQL. Open your terminal and run the following command:","title":"Setting Up Drizzle on an RPC Server"},{"content":"In this tutorial, we\u0026rsquo;ll create a simple JSON-RPC API using TypeScript and Express, leveraging the typed-rpc library for easy RPC handling. We will also create a client to interact with our API. By the end, you\u0026rsquo;ll have a fully functional API that can respond to requests.\nPrerequisites Node.js installed on your machine (version 16 or higher). Basic knowledge of TypeScript and JavaScript. Step 1: Set Up Your Project Create a new directory for your project and navigate into it:\nmkdir typed-rpc-api cd typed-rpc-api Initialize a new Node.js project:\nnpm init -y Install the required packages:\nnpm install express typed-rpc npm install --save-dev typescript @types/node @types/express ts-node Create a TypeScript configuration file named tsconfig.json:\n{ \u0026#34;compilerOptions\u0026#34;: { \u0026#34;target\u0026#34;: \u0026#34;ESNext\u0026#34;, \u0026#34;module\u0026#34;: \u0026#34;Node16\u0026#34;, \u0026#34;moduleResolution\u0026#34;: \u0026#34;Node16\u0026#34;, \u0026#34;strict\u0026#34;: true, \u0026#34;esModuleInterop\u0026#34;: true, \u0026#34;skipLibCheck\u0026#34;: true, \u0026#34;forceConsistentCasingInFileNames\u0026#34;: true, \u0026#34;outDir\u0026#34;: \u0026#34;./dist\u0026#34;, \u0026#34;rootDir\u0026#34;: \u0026#34;./src\u0026#34;, \u0026#34;noEmit\u0026#34;: true, \u0026#34;allowImportingTsExtensions\u0026#34;: true }, \u0026#34;include\u0026#34;: [\u0026#34;src/**/*\u0026#34;] } Implement the API Create the API entry point at src/api/index.ts:\nimport express from \u0026#34;express\u0026#34;; import { handleRpc } from \u0026#34;typed-rpc/server\u0026#34;; import { myService } from \u0026#34;./service\u0026#34;; const app = express(); app.use(express.json()); app.post(\u0026#34;/api\u0026#34;, (req, res, next) =\u0026gt; { handleRpc(req.body, myService) .then((result) =\u0026gt; res.json(result)) .catch(next); }); const PORT = process.env.PORT || 3000; app.listen(PORT, () =\u0026gt; { console.log(`Server is running on http://localhost:${PORT}`); }); Define your service in src/api/service.ts:\nexport const myService = { greet: async (name: string): Promise\u0026lt;string\u0026gt; =\u0026gt; { return `Hello, ${name}!`; }, }; export type MyService = typeof myService; Create the Client Set up the client in src/client/index.ts:\nimport { rpcClient } from \u0026#34;typed-rpc\u0026#34;; import type { MyService } from \u0026#34;../api/service\u0026#34;; const client = rpcClient\u0026lt;MyService\u0026gt;(\u0026#34;http://localhost:3000/api\u0026#34;); async function callApi() { const result = await client.greet(\u0026#34;Ozan\u0026#34;); console.log(result); // Output: Hello, Ozan! } callApi(); Add Scripts to package.json Update your package.json to include a start script:\n\u0026#34;scripts\u0026#34;: { \u0026#34;start\u0026#34;: \u0026#34;ts-node src/api/index.ts\u0026#34; } Run Your API Start your server:\nnpm run start Test the API using cURL: Open another terminal window and run the following command:\ncurl -X POST http://localhost:3000/api -H \u0026#34;Content-Type: application/json\u0026#34; -d \u0026#39;{ \u0026#34;jsonrpc\u0026#34;: \u0026#34;2.0\u0026#34;, \u0026#34;method\u0026#34;: \u0026#34;greet\u0026#34;, \u0026#34;params\u0026#34;: [\u0026#34;Ozan\u0026#34;], \u0026#34;id\u0026#34;: 1 }\u0026#39; You should receive a response like this:\n{ \u0026#34;jsonrpc\u0026#34;: \u0026#34;2.0\u0026#34;, \u0026#34;id\u0026#34;: 1, \u0026#34;result\u0026#34;: \u0026#34;Hello, Ozan!\u0026#34; } Advanced Usage Sending Custom Headers Clients can send custom headers using a getHeaders function:\nconst client = rpcClient\u0026lt;MyService\u0026gt;({ url: \u0026#34;/api\u0026#34;, getHeaders() { return { Authorization: auth }; }, }); Tip: The getHeaders function can also be async.\nAborting Requests Abort requests by passing the Promise to client.$abort():\nconst client = rpcClient\u0026lt;HelloService\u0026gt;(url); const res = client.hello(\u0026#34;world\u0026#34;); client.$abort(res); Error Handling In case of an error, the client throws an RpcError with message, code, and optionally data. Customize errors with RpcHandlerOptions or provide an onError handler for logging.\nFor internal errors (invalid request, method not found), the error code follows the specs.\nCORS Credentials Include credentials in cross-origin requests with credentials: \u0026lsquo;include\u0026rsquo;.\nConclusion In this tutorial, we successfully set up a JSON-RPC API using TypeScript and Express. We created a simple service that responds to a greeting request and built a client to interact with the API. This setup can serve as a foundation for building more complex applications using RPC communication.\n","permalink":"http://localhost:1313/posts/trpc/","summary":"In this tutorial, we\u0026rsquo;ll create a simple JSON-RPC API using TypeScript and Express, leveraging the typed-rpc library for easy RPC handling. We will also create a client to interact with our API. By the end, you\u0026rsquo;ll have a fully functional API that can respond to requests.\nPrerequisites Node.js installed on your machine (version 16 or higher). Basic knowledge of TypeScript and JavaScript. Step 1: Set Up Your Project Create a new directory for your project and navigate into it:","title":"Building a JSON-RPC API with TypeScript and Express"},{"content":"React Router is an essential library for building single-page applications (SPAs) in React. It provides a robust way to manage navigation, routes, and data fetching. In this guide, we’ll explore the createBrowserRouter API, its features like loaders and actions, and how it compares to using React Query for data management. To get started, install React Router if you haven’t already: npm install react-router-dom\nWhat is createBrowserRouter? createBrowserRouter is a part of React Router that simplifies route management in your React applications. It allows you to define routes declaratively and manage complex routing scenarios with ease.\nKey Features of createBrowserRouter 1- Declarative Routing: It allows you to define routes in a more declarative manner, making your code easier to read and maintain.\nimport { createBrowserRouter, RouterProvider } from \u0026#34;react-router-dom\u0026#34;; import Home from \u0026#34;./Home\u0026#34;; import About from \u0026#34;./About\u0026#34;; const router = createBrowserRouter([ { path: \u0026#34;/\u0026#34;, element: \u0026lt;Home /\u0026gt;, }, { path: \u0026#34;/about\u0026#34;, element: \u0026lt;About /\u0026gt;, }, ]); function App() { return \u0026lt;RouterProvider router={router} /\u0026gt;; } 2- Nested Routes: It provides better support for nested routing, enabling you to create complex UIs with less boilerplate code.\nconst router = createBrowserRouter([ { path: \u0026#34;/\u0026#34;, element: \u0026lt;Layout /\u0026gt;, children: [ { path: \u0026#34;dashboard\u0026#34;, element: \u0026lt;Dashboard /\u0026gt;, }, { path: \u0026#34;settings\u0026#34;, element: \u0026lt;Settings /\u0026gt;, }, ], }, ]); 3- Data Loading: The API integrates data loading and route handling, allowing you to fetch data directly as part of the routing process. This streamlines the data-fetching strategy.\nconst router = createBrowserRouter([ { path: \u0026#34;/user/:id\u0026#34;, element: \u0026lt;UserProfile /\u0026gt;, loader: async ({ params }) =\u0026gt; { const response = await fetch(`/api/users/${params.id}`); return response.json(); }, }, ]); 4- Error Handling: It simplifies error handling by allowing you to define error boundaries at the route level, making it easier to manage errors in your application.\nconst router = createBrowserRouter([ { path: \u0026#34;/dashboard\u0026#34;, element: \u0026lt;Dashboard /\u0026gt;, errorElement: \u0026lt;ErrorPage /\u0026gt;, // Custom error page component }, ]); 5- Asynchronous Routing: It supports asynchronous route loading, which helps improve performance by splitting code and loading only what is necessary for the current route.\nconst router = createBrowserRouter([ { path: \u0026#34;/lazy\u0026#34;, element: ( \u0026lt;React.Suspense fallback={\u0026lt;Loading /\u0026gt;}\u0026gt; \u0026lt;LazyComponent /\u0026gt; \u0026lt;/React.Suspense\u0026gt; ), }, ]); 6- Type Safety: If you\u0026rsquo;re using TypeScript, createBrowserRouter offers better type inference, reducing runtime errors and improving developer experience.\nimport { createBrowserRouter, RouteObject } from \u0026#34;react-router-dom\u0026#34;; const routes: RouteObject[] = [ { path: \u0026#34;/\u0026#34;, element: \u0026lt;Home /\u0026gt;, }, { path: \u0026#34;/about\u0026#34;, element: \u0026lt;About /\u0026gt;, }, ]; const router = createBrowserRouter(routes); 7- Improved Flexibility: The router can handle various routing scenarios, including redirects and route transitions, with a more flexible API.\nconst router = createBrowserRouter([ { path: \u0026#34;/\u0026#34;, element: \u0026lt;Home /\u0026gt;, }, { path: \u0026#34;/old-about\u0026#34;, redirect: \u0026#34;/about\u0026#34;, // Redirect from old to new route }, ]); Loaders Loaders are functions that fetch data before a route is rendered\nimport { createBrowserRouter, RouterProvider } from \u0026#34;react-router-dom\u0026#34;; const loadUserData = async ({ params }) =\u0026gt; { const response = await fetch(`/api/users/${params.id}`); if (!response.ok) { throw new Response(\u0026#34;User not found\u0026#34;, { status: 404 }); } return response.json(); }; const UserProfile = ({ data }) =\u0026gt; ( \u0026lt;div\u0026gt; \u0026lt;h1\u0026gt;{data.name}\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;{data.email}\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; ); const router = createBrowserRouter([ { path: \u0026#34;/user/:id\u0026#34;, element: \u0026lt;UserProfile /\u0026gt;, loader: loadUserData, }, ]); function App() { return \u0026lt;RouterProvider router={router} /\u0026gt;; } Actions Actions are functions that handle form submissions and other interactions.\nconst submitUserData = async ({ request }) =\u0026gt; { const formData = await request.formData(); const response = await fetch(\u0026#34;/api/users\u0026#34;, { method: \u0026#34;POST\u0026#34;, body: formData, }); if (!response.ok) { throw new Response(\u0026#34;Failed to create user\u0026#34;, { status: 400 }); } return response.json(); }; const CreateUser = () =\u0026gt; ( \u0026lt;form method=\u0026#34;post\u0026#34; action=\u0026#34;/create-user\u0026#34;\u0026gt; \u0026lt;input name=\u0026#34;name\u0026#34; placeholder=\u0026#34;Name\u0026#34; required /\u0026gt; \u0026lt;input name=\u0026#34;email\u0026#34; placeholder=\u0026#34;Email\u0026#34; required /\u0026gt; \u0026lt;button type=\u0026#34;submit\u0026#34;\u0026gt;Create User\u0026lt;/button\u0026gt; \u0026lt;/form\u0026gt; ); const router = createBrowserRouter([ { path: \u0026#34;/create-user\u0026#34;, element: \u0026lt;CreateUser /\u0026gt;, action: submitUserData, }, ]); Comparison with React Query Using React Query React Query provides advanced features like caching, background data fetching, and global state management. Here’s a brief comparison:\nPros of React React Router: Integrated with Routing: Loaders are tied directly to route definitions, making it easy to fetch data when navigating to a specific route. Simplicity: For basic data fetching needs, using loaders keeps your code straightforward by centralizing data fetching logic alongside route definitions. Automatic Data Fetching: Data is automatically fetched when navigating to a route, which can simplify the component logic. Cons of React Router: Limited Features: Loaders lack advanced features like caching, background refetching, and automatic retries that are standard in dedicated data-fetching libraries. No Global State Management: Loaders do not provide a way to manage global state or share data across multiple components without re-fetching. Less Flexibility: They are designed for fetching data on route changes, which may not cover all use cases for data fetching in a more complex application. Conclusion createBrowserRouter is a powerful addition to React Router, simplifying routing and data fetching in your applications. With features like loaders and actions, it enhances your ability to manage complex UIs effectively. While React Query provides advanced data fetching capabilities, combining both can lead to a well-structured and efficient application.\nBy understanding the strengths of each tool, you can make informed decisions on how to structure your React applications for optimal performance and maintainability.\n","permalink":"http://localhost:1313/posts/react-router/","summary":"React Router is an essential library for building single-page applications (SPAs) in React. It provides a robust way to manage navigation, routes, and data fetching. In this guide, we’ll explore the createBrowserRouter API, its features like loaders and actions, and how it compares to using React Query for data management. To get started, install React Router if you haven’t already: npm install react-router-dom\nWhat is createBrowserRouter? createBrowserRouter is a part of React Router that simplifies route management in your React applications.","title":"Understanding React Router: Complete Guide to createBrowserRouter"},{"content":"In this article, we will walk through the steps to create a simple RESTful API using Node.js with Express, backed by a PostgreSQL database, all running in Docker containers. This setup allows for easy development and deployment, ensuring consistency across environments.\nStep 1: Set Up Your Project Create a project directory:\nmkdir express-postgres-api cd express-postgres-api Initialize a Node.js project:\nnpm init -y npm install express pg dotenv npm i -D nodemon cat package.json Step 2: Create the Express Application Create a new file named app.js: // app.js const express = require(\u0026#34;express\u0026#34;); const { Pool } = require(\u0026#34;pg\u0026#34;); const dotenv = require(\u0026#34;dotenv\u0026#34;); dotenv.config(); const app = express(); const port = process.env.PORT || 3000; // Middleware app.use(express.json()); // PostgreSQL connection const pool = new Pool({ user: process.env.DB_USER, host: process.env.DB_HOST, database: process.env.DB_NAME, password: process.env.DB_PASSWORD, port: process.env.DB_PORT, }); // Basic route app.get(\u0026#34;/\u0026#34;, (req, res) =\u0026gt; { res.send(\u0026#34;Hello World!\u0026#34;); }); // Get all items app.get(\u0026#34;/items\u0026#34;, async (req, res) =\u0026gt; { try { const result = await pool.query(\u0026#34;SELECT * FROM items\u0026#34;); res.json(result.rows); } catch (err) { console.error(err); res.status(500).send(\u0026#34;Server error\u0026#34;); } }); // Start the server app.listen(port, () =\u0026gt; { console.log(`Server running on http://localhost:${port}`); }); Create a .env file: In the project root, create a .env file to store your database configuration:\nDB_USER=pguser DB_HOST=db DB_NAME=pgdb DB_PASSWORD=pgpassword DB_PORT=5432 PORT=3000 Step 3: Create Docker Setup Next, we’ll configure Docker to run our application and database.\ndockerfile FROM node:14 WORKDIR /usr/src/app COPY package*.json ./ RUN npm install COPY . . CMD [\u0026#34;npm\u0026#34;, \u0026#34;run\u0026#34;, \u0026#34;dev\u0026#34;] docker-compose.yml This file will define the services for both the API and the PostgreSQL database:\n#version: \u0026#34;3.8\u0026#34; services: db: image: postgres:alpine environment: POSTGRES_USER: ${DB_USER} POSTGRES_PASSWORD: ${DB_PASSWORD} POSTGRES_DB: ${DB_NAME} ports: - \u0026#34;5432:5432\u0026#34; volumes: - pgdata:/var/lib/postgresql/data api: build: . ports: - \u0026#34;3000:3000\u0026#34; environment: - DB_USER=${DB_USER} - DB_HOST=${DB_HOST} - DB_NAME=${DB_NAME} - DB_PASSWORD=${DB_PASSWORD} - DB_PORT=${DB_PORT} depends_on: - db volumes: pgdata: Step 4: Create the Database Table Launch the Docker containers: docker compose up -d docker compose down # stopping the containers docker compose --build # re-building containers after any change is done Connect to the PostgreSQL container: Use the following command to access the PostgreSQL shell:\ndocker exec -it {db_container_name} psql -U {user_name} -d {db_name} docker exec -it express-postgres-api-db-1 psql -U pguser -d pgdb Create the items table and basic queries: Execute the following SQL commands:\nCREATE TABLE items ( id SERIAL PRIMARY KEY, name VARCHAR(100) NOT NULL ); insert into items (1, \u0026#39;tom\u0026#39;); select * from items; Step 5: Testing the API Now, let’s test our API to ensure everything is working as expected. We will use curl.\ndocker compose -d up curl http://localhost:3000 curl http://localhost:3000/items Conclusion In this tutorial, we successfully set up a simple RESTful API using Node.js, Express, and PostgreSQL, all running within Docker containers. This setup simplifies the development process and ensures that the application behaves consistently across different environments.\n","permalink":"http://localhost:1313/posts/node-express-api-docker/","summary":"In this article, we will walk through the steps to create a simple RESTful API using Node.js with Express, backed by a PostgreSQL database, all running in Docker containers. This setup allows for easy development and deployment, ensuring consistency across environments.\nStep 1: Set Up Your Project Create a project directory:\nmkdir express-postgres-api cd express-postgres-api Initialize a Node.js project:\nnpm init -y npm install express pg dotenv npm i -D nodemon cat package.","title":"Setting Up a Simple Node.js Express Api and PostgreSql database with Docker"},{"content":"Advanced Types TypeScript offers a robust type system that helps developers catch errors early and improve code quality. One of the powerful features of TypeScript is its advanced types, which include constructs like as const, tuples, generics, and built-in types. In this post, we’ll explore these concepts with code snippets for clarity.\nAs Const The as const assertion allows you to create immutable types. For example, while a normal variable can be mutable, using as const makes its properties read-only. This is particularly useful when creating enums or constant values.\nlet a: number = 4; // a is mutable const b = 5; // b is not mutable const c = 5 as const; // this is what actually happens behind the sceen const num = [\u0026#34;1\u0026#34;, \u0026#34;2\u0026#34;, \u0026#34;3\u0026#34;] as const; // num.push(\u0026#39;4\u0026#39;) is still valid witout as const const object = { name: \u0026#34;\u0026#34;, age: 35, adress: { street: \u0026#34;\u0026#34; } } as const; // as const make every property as read only This can be effective for creating enums:\nconst LEVELS = [\u0026#34;begginer\u0026#34;, \u0026#34;intermadiate\u0026#34;, \u0026#34;advanced\u0026#34;] as const; // type LEVELS = [\u0026#39;begginer\u0026#39; | \u0026#39;intermadiate\u0026#39;| \u0026#39;advanced\u0026#39; } type Person = { skillLevel: (typeof LEVELS)[number] }; // can be assigned to variable LEVELS.forEach((level) =\u0026gt; console.log(level)); // this can be iterated unlice type Tuples Tuples are fixed-length arrays with specific types. They can be useful for representing structured data.\ntype Tuple = [string, boolean]; const person: Tuple = { name: \u0026#34;John\u0026#34;, age: 35 }; Object.entries(person).forEach(([key, value]) =\u0026gt; { console.log(key, value); }); // type Tuple = [string, boolean] ,note that useState returns tupple Generics Generics enable you to create reusable components that can work with any data type. The is an example of a generic type.\nconst input = document.querySelector\u0026lt;HTMLInputElement\u0026gt;(\u0026#34;.input\u0026#34;); console.log(input); With functions, generics allow for flexibility:\nfunction getSecond\u0026lt;T\u0026gt;(array: T[]): T { array[1]; } const a = [1, 2, 3]; // returns 2 (T is number) const b = [\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;]; // returns b (T is string) A practical use case for generics is in API responses:\ntype APIResponse\u0026lt;TData\u0026gt; = { data: TData; error: boolean; }; const a: APIResponse\u0026lt;Array\u0026lt;number\u0026gt;\u0026gt; = { data: [1, 2, 3], isError: false }; Async Functions TypeScript can infer return types for async functions, making code cleaner and more readable.\nfunction wait(duration: number) { return new Promise\u0026lt;string\u0026gt;((res) =\u0026gt; { setTimeout(() =\u0026gt; res(\u0026#34;hi!\u0026#34;), duration); }); } wait(1000).then((value) =\u0026gt; { console.log(value.length); }); Build in Types TypeScript provides built-in utility types like Omit, Pick, Partial, and Required to manipulate types easily.\nOmit and Pick To create a new type based on an existing one, you can use Pick or Omit:\ntype NewTodo = Pick\u0026lt;Todo, \u0026quot;name\u0026quot; | \u0026quot;completed\u0026quot;\u0026gt; type NewTodo = Omit\u0026lt;Todo, \u0026quot;id\u0026quot;\u0026gt;\ntype Todo = { id:string; name:string; completed:boolean } type NewTodo = { name:string; completed:boolean; } function saveTodo(newTodo: NewTodo) { return {...newTodo, id:crypto.randomUUID() } Partial and Required To make properties optional or required:\ntype Todo = { title?: string; completed: boolean; address?: { street?: street; }; }; type RequiredPick\u0026lt;T, Key extends keyof T\u0026gt; = Required\u0026lt;Pick\u0026lt;T, Key\u0026gt;\u0026gt; \u0026amp; T; // we pick one of the keys from Todo type and make it required, lastly make it union with Todo but required overwrites so this code makes generic picked type as required. type FormTodo = RequiredPick\u0026lt;Todo, \u0026#34;title\u0026#34;\u0026gt;; // now title is require, it is not optional anymore type PartialPick\u0026lt;T, Key extends keyof T\u0026gt; = Partial\u0026lt;Pick\u0026lt;T, Key\u0026gt;\u0026gt; \u0026amp; Omit\u0026lt;T, Key\u0026gt;; // we pick one key and make it partial, lastly we union with all of the keys but it would overwrite required so we omit the specific key before unioning type FormTodo2 = PartialPick\u0026lt;Todo, \u0026#34;completed\u0026#34;\u0026gt;; // now completed is optional ReturnType and Parameters TypeScript allows you to extract the return type of a function or its parameters using ReturnType and Parameters.\nconst Func = () =\u0026gt; void type ReturnTypeOfFunc = ReturnType\u0026lt;typeof Func\u0026gt; // function checkLength(a: string, b: number) { return a.length() \u0026gt; b; } type ParamsOfCheckLen = Parameters\u0026lt;typeof CheckLength\u0026gt;; // [a:string, b:number] // a tupple Record The Record type is useful for creating objects with specific keys and values.\ntype PeopleGroupByName = Record\u0026lt;Person[\u0026#34;name\u0026#34;], Person[]\u0026gt;; Readonly The Readonly type creates immutable versions of existing types. This is basically same as const but readonly can be used for creating another type.\ntype FinalTodo = Readonly\u0026lt;Todo\u0026gt;; Type Narrowing Type narrowing allows for more precise type checking in your code. Basic type guards help differentiate types effectively.\nBasic Type Guards type Todo = { titles: string; property: \u0026#34;High\u0026#34; | \u0026#34;Normal\u0026#34; | \u0026#34;Low\u0026#34;; isComplete: boolean; description?: string; dueDate: Date | string; }; function extendTodo(todo: Todo) { if (typeof todo.dueDate === \u0026#34;string\u0026#34;) { // or todo.dueDate instanceof Date } else { console.log(todo.dueDate.getDate); } } checking undefined is possible with ?. Below code is equivalent to todo.description?.length \u0026gt; 5 if(todo.description !== undefined) { todo.description.length \u0026gt; 5 // length is not exist but it will not give error since we check if it is undefined but this is possible with todo.description?.length \u0026gt; 5 This ! also tell tsc that it is not possible be to be null but it overwrites typescript Discriminated Union Discriminated unions simplify handling different types:\ntype SuccessResponse = { status: \u0026#34;Success\u0026#34;; data: { id: string; name: string }; }; type ErrorResponse = { status: \u0026#34;Error\u0026#34;; errorMessage: string; }; type UserApiResponse = SuccessResponse | ErrorResponse; Function Overloads Function overloads allow you to define multiple ways to call a function based on different input types.\nfunction sum = (nums:number[]):number function sum = (a:number,b:number):number const t1 = sum([20,22]); const t2 = sum(20,22); Conclusion Understanding advanced types in TypeScript enhances code quality and maintainability. By leveraging features like as const, generics, utility types, and type narrowing, developers can write more robust and error-resistant applications. Embrace these tools to improve your TypeScript skills!\n","permalink":"http://localhost:1313/posts/typescript/","summary":"Advanced Types TypeScript offers a robust type system that helps developers catch errors early and improve code quality. One of the powerful features of TypeScript is its advanced types, which include constructs like as const, tuples, generics, and built-in types. In this post, we’ll explore these concepts with code snippets for clarity.\nAs Const The as const assertion allows you to create immutable types. For example, while a normal variable can be mutable, using as const makes its properties read-only.","title":"Understanding Advanced Types in TypeScript"},{"content":"I have build my first mobile app with React Native top of Expo framework. I have used Redux for state management and Tailwind for User Interface design. I have published it on Google Store. You can ger the app here\nBislingo ✓ Development: Developing your own vocabulary base on your interest help you master at language faster.\n✓ Entertaintment: Games can make it easier to learn educational contents and develop cognitive skills.\n✓ Interactivity: Quizzes help you identify what you know and what you don\u0026rsquo;t know\n✓ Entertaintment: Games can make it easier to learn educational contents and develop cognitive skills.\nNot just a regular dictionary app. You can build your own dictionary as you like. You can use it for any language you want. Moreover BisLingo has its own quiz builder that can produce random questions with your own entries and you can also practice your knowledge by playing hangman.\nI believe that BisLingo will revolutionize the way you learning language, and I can\u0026rsquo;t wait for you to try it out for yourself. Download it now and experience the convenience and ease of BisLingo. Thank you for your support, and please don\u0026rsquo;t hesitate to contact us with any questions or feedback. Sincerely, The developer of Bislingo\n","permalink":"http://localhost:1313/projects/building-mobile-app-with-expo-and-react-native/","summary":"I have build my first mobile app with React Native top of Expo framework. I have used Redux for state management and Tailwind for User Interface design. I have published it on Google Store. You can ger the app here\nBislingo ✓ Development: Developing your own vocabulary base on your interest help you master at language faster.\n✓ Entertaintment: Games can make it easier to learn educational contents and develop cognitive skills.","title":"Building Mobile App With Expo and React Native"},{"content":"I have built my personal website with Next framwork and React library, you can visit my website at oocak.com\nReact and Next.js are a great combination for building modern web applications. Here\u0026rsquo;s why they make a perfect couple and a tutorial on how to set up a Next.js app with a simple React user interface.\nReact and Next.js 1. Server-side Rendering (SSR): Next.js provides server-side rendering out of the box, which can improve the initial load time and search engine optimization (SEO) of your application, as opposed to a purely client-side React application.\n2. Static Site Generation (SSG): Next.js allows you to pre-render pages at build-time, creating highly performant \u0026ldquo;static\u0026rdquo; pages that can be served directly from a CDN.\n3. Routing and File-based Routing: Next.js has a file-based routing system, which makes it easy to set up and maintain the navigation structure of your application.\n4. Automatic Code Splitting: Next.js automatically splits your application\u0026rsquo;s code, reducing the amount of JavaScript that needs to be downloaded on each page load.\n5. Image Optimization: Next.js provides built-in image optimization, which can significantly improve the performance of your application.\n6. Seamless Integration with React: Next.js is built on top of React, so you can leverage all the power and flexibility of the React ecosystem. Tutorial: Setting up a Next.js App with a Simple React User Interface\nbrew install node npx create-next-app my-app This will create a new directory called my-app with the necessary files and folders for a Next.js application.\nDevelop the React User Interface: Next.js uses the pages directory to define your application\u0026rsquo;s routes. Open the pages directory and create a new file called index.js. In this file, you can build your React user interface:\nimport React from \u0026#39;react\u0026#39;; const HomePage = () =\u0026gt; { return ( \u0026lt;div\u0026gt; \u0026lt;h1\u0026gt;Welcome to my Next.js App\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;This is a simple React user interface built with Next.js.\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; ); }; export default HomePage; Run the Development Server: In your terminal, navigate to the my-app directory and run the following command to start the development server:\nnpm run dev This will start the Next.js development server and open your application in your default web browser.\nStatic Site Generation: Create pre-rendered pages at build-time using the getStaticProps or getStaticPaths functions.\nServer-side Rendering: Render pages on the server using the getServerSideProps function.\nAPI Routes: Create serverless API routes using the pages/api directory.\nStyling: Integrate CSS, Sass, or other styling solutions into your Next.js application.\nDeployment: Deploy your Next.js app to popular hosting platforms like Vercel, Netlify, or AWS. By combining the power of React and the features of Next.js, you can create high-performance, scalable web applications with a seamless user experience.\n","permalink":"http://localhost:1313/projects/building-personal-website-with-next-and-react/","summary":"I have built my personal website with Next framwork and React library, you can visit my website at oocak.com\nReact and Next.js are a great combination for building modern web applications. Here\u0026rsquo;s why they make a perfect couple and a tutorial on how to set up a Next.js app with a simple React user interface.\nReact and Next.js 1. Server-side Rendering (SSR): Next.js provides server-side rendering out of the box, which can improve the initial load time and search engine optimization (SEO) of your application, as opposed to a purely client-side React application.","title":"Building Personal Website With Next and React"},{"content":"Setting Up Hugo We need brew, go, git and hugo to build a Hugo website. I assume we already have bre and git are installed in our operating system.\nbrew install go go version brew install hugo hugo version hugo new site myspace code . Create Custom Layout Create a markdown file named as _index.md under content folder\n--- title: Home --- Hello World!!! and about.md with title: About then create default layout as baseof.html under /layouts/_default/ folder\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34; /\u0026gt; \u0026lt;meta http-equiv=\u0026#34;X-UA-Compatible\u0026#34; content=\u0026#34;IE=edge\u0026#34; /\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1.0\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;{{.Page.Title}}\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; {{ block \u0026#34;main\u0026#34; . }} {{ end }} \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; create two more html files under _default folder list.html for landing page and single.html for about page with below content\n{{ define \u0026#34;main\u0026#34;}} {{ .Content}} {{ end }} Stylesheet {{ $style := resources.Get \u0026#34;sass/main.scss\u0026#34; | resources.ToCSS | resources.Minify }} \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;{{ $style.Permalink }}\u0026#34; /\u0026gt; then create main.scss under assets/sass/ folder\nbody { width: 400px; margin: 0 auto; font-family: sans-serif; } Partials Create a file name as nav.html under /layoutes/partials/\n\u0026lt;nav\u0026gt; \u0026lt;ul\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;/\u0026#34;\u0026gt;Home\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;/about/\u0026#34;\u0026gt;About\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/nav\u0026gt; then add below line in the baseof.html\n{{ partial \u0026#34;nav.html\u0026#34; }} we can also create meta partial as meta.html\n\u0026lt;meta charset=\u0026#34;utf-8\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;{{ print .Page.Title }}\u0026lt;/title\u0026gt; {{ $style := resources.Get \u0026#34;sass/main.scss\u0026#34; | resources.ToCSS | resources.Minify }} \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;{{ $style.Permalink }}\u0026#34; /\u0026gt; then add snippet in baseof.html\n{{ partial \u0026#34;meta.html\u0026#34; . }} That little . at the end is passing the context of the current page, which allows the partial to print out the current page’s title.\nTemplate \u0026lt;title\u0026gt;{{ .Params.title }} | {{ .Site.title }}\u0026lt;/title\u0026gt; \u0026lt;p\u0026gt;you can use double curly braces like this: {{ \u0026#34;Hello!\u0026#34; }}.\u0026lt;/p\u0026gt; {{ if isset .Params \u0026#34;title\u0026#34; }} \u0026lt;title\u0026gt;{{ .Params.title }}\u0026lt;/title\u0026gt; {{ else }} \u0026lt;title\u0026gt;{{ .Site.title }}\u0026lt;/title\u0026gt; {{ end }} {{ $favorite_food := \u0026#34;Gazelle\u0026#34; }} {{ $favorite_food }} {{ $best_friends := slice \u0026#34;pumbaa\u0026#34; \u0026#34;timon\u0026#34; \u0026#34;nala\u0026#34; \u0026#34;rafiki\u0026#34; }} \u0026lt;ul\u0026gt; {{ range $best_friends }} \u0026lt;li\u0026gt;{{ . }}\u0026lt;/li\u0026gt; {{ end }} \u0026lt;/ul\u0026gt; to create conditiotonal templeting, enter params in config.toml or hugo.toml file\n[params] name = \u0026#39;Functor\u0026#39; then create a footer.html partial where footer will only seen if params is exist\n{{ with .Params.hide_footer }} \u0026lt;!-- No footer here! --\u0026gt; {{ else }} \u0026lt;footer\u0026gt;Website made by {{ .Site.Params.name }} in {{ now.Year }}\u0026lt;/footer\u0026gt; {{ end }} then add the partial in baseof.html\n{{ partial \u0026#34;footer.html\u0026#34; . }} we can hide footer in any html page(content) adding hide_footer just below title\nhide_footer: true Creating Blog cretate a file name as _index.md under /content/posts/\n--- title: Blog --- this markdown file will follow the rules of list.html unde /layouts/_default/ folder we can create our spesific layout if we also create list.html under /layout/posts folder\n{{ define \u0026#34;main\u0026#34;}} {{ .Content}} {{ end }} but we can also create single.html under /layout/posts/ folder so every post will follow the rules of single.html file\u0026rsquo;s rules\n{{ define \u0026#34;main\u0026#34;}} {{ .Content}} {{ end }} Using Available Layouts Above we can see basic hugo structure, alternatively we can use a theme to be able to see the site\nhugo new site myspace cd myspace git init git submodule add https://github.com/theNewDynamic/gohugo-theme-ananke.git themes/ananke echo \u0026#34;theme = \u0026#39;ananke\u0026#39;\u0026#34; \u0026gt;\u0026gt; hugo.toml hugo server we can also use git clone instead of fit submodule add\nyou can refer from https://gohugo.io/getting-started/quick-start/ echo \u0026#34;theme = \u0026#39;ananke\u0026#39;\u0026#34; \u0026gt;\u0026gt; hugo.toml or directly place below code to hugo.toml before running hugo server\ntheme: [\u0026#34;PaperMod\u0026#34;] delete draft = true or assign false to add content and publish it(files in public folder)\nhugo new content posts/my-first-post.md hugo server hugo when we created new post in terminal, the current time automatically created but if we like to create a file with default fron matter, we can add default fron matter in default.md under archtypes folder so next time when we create a file with hugo new content comment, all the fron matter will be added.\ntitle : \u0026#39;{{ replace .File.ContentBaseName \u0026#34;-\u0026#34; \u0026#34; \u0026#34; | title }}\u0026#39; date : {{ .Date }} draft : true author: [\u0026#34;Ozan\u0026#34;] Hugo.toml Hugo.toml is a configuration file where we can define navigation, profile module and more.\nPublishing Website to Netlify After finishing the development of vebsite we can create public directory with hugo on terminal. The public directory will contain all the html, css, javascript and static files for the website, however we will upload our files to netlify so we can delete the public directory.\nhugo rm -rf ./public/ git init touch .gitmodules We need to initialize git file to push our filese to github then later we will connect the github repository to netlify. We also need to create a .gitmodules to define the theme for git.\n[submodule \u0026#34;themes/PaperMod\u0026#34;] path = themes/PaperMod url = \u0026#34;htps://github.com/adityatelange/hugo-PaperMod.git\u0026#34; Then we can push our project to github.\nFinally we can go to Netlify and click add new site, then import existing project and then log in with desired third party application, and then we can search our project in github. You can refer here.\nbase directory = build command = hugo publish directory = public HUGO_VERSION = hugo verion in terminal\n","permalink":"http://localhost:1313/posts/how-to-build-hugo-website/","summary":"Setting Up Hugo We need brew, go, git and hugo to build a Hugo website. I assume we already have bre and git are installed in our operating system.\nbrew install go go version brew install hugo hugo version hugo new site myspace code . Create Custom Layout Create a markdown file named as _index.md under content folder\n--- title: Home --- Hello World!!! and about.md with title: About then create default layout as baseof.","title":"How to Build Hugo Website"}]